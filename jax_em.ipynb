{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "56a60125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5b7a2",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "24480cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def load_synthetic_dataset(filename):\n",
    "    data = np.load(filename)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data)\n",
    "    data = scaler.transform(data)\n",
    "    return data\n",
    "\n",
    "def load_cloud_dataset():\n",
    "    cloud_data_name = 'cloud.data'\n",
    "    with open(cloud_data_name) as f:\n",
    "        cloud_data = pd.DataFrame([item.split() for item in f.readlines()])\n",
    "    cloud_data = cloud_data.astype(float).to_numpy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(cloud_data)\n",
    "    cloud_data = scaler.transform(cloud_data)\n",
    "    return cloud_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3a423",
   "metadata": {},
   "source": [
    "### Jax GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "c976ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import kmeans_plusplus\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class GuassianMixture:\n",
    "    def __init__(self, dim, n_comp, n_init, verbose=False):\n",
    "        self.dim = dim\n",
    "        self.n_comp = n_comp\n",
    "        self.means = None\n",
    "        self.cov = None\n",
    "        self.weigths = None\n",
    "        self.n_init = n_init\n",
    "        self.verbose = verbose\n",
    "        self.is_init = False\n",
    "\n",
    "    def fit(self, data, max_iter):\n",
    "        \n",
    "        if not self.is_init:\n",
    "            self.km_init(data)\n",
    "            \n",
    "        new_weights, new_means, new_cov = [], [], []\n",
    "        for i in range(max_iter):\n",
    "            for j in range(self.n_init):\n",
    "                log_lik = self.loglikelihood(data, j)\n",
    "                new_weights_j, new_means_j, new_cov_j = self.em_step(log_lik, data, self.weights[j], self.means[j], self.cov[j])\n",
    "                new_weights.append(new_weights_j)\n",
    "                new_means.append(new_means_j)\n",
    "                new_cov.append(new_cov_j)\n",
    "                \n",
    "            self.weights = jnp.asarray(new_weights)\n",
    "            self.means = jnp.asarray(new_means)\n",
    "            self.cov = jnp.asarray(new_cov)\n",
    "#             print(self.score(data))\n",
    "        \n",
    "    def em_step(self, log_lik, data, weigths, means, cov):\n",
    "        # Expectation\n",
    "        new_z = jax.nn.softmax(log_lik, 0)\n",
    "        # Minimization\n",
    "        # Weights\n",
    "        new_weights = jnp.mean(new_z, 1)\n",
    "        \n",
    "        # Means\n",
    "        mul = jax.vmap(lambda x, y: jnp.expand_dims(x, 1) * y, (0, None), 0)\n",
    "        new_mu = jnp.sum(mul(new_z, data), 1) / jnp.expand_dims(jnp.sum(new_z, 1), 1)\n",
    "        \n",
    "        # Sigma\n",
    "        outer_product_helper_1 = jax.vmap(lambda data, mu, z: z * jnp.expand_dims((data - mu), 1) @ jnp.expand_dims((data - mu), 1).T, (None, 0, 0), 0)\n",
    "        outer_product_helper_2 = jax.vmap(outer_product_helper_1, (0, None, 0), 0)\n",
    "        new_sigma = jnp.sum(outer_product_helper_2(data, new_mu, new_z.T), axis=0) / jnp.expand_dims(jnp.sum(new_z, 1), (1, 2))\n",
    "        \n",
    "        return new_weights, new_mu, new_sigma\n",
    "            \n",
    "    def k_pp_init(self, data):\n",
    "        means = []\n",
    "        for i in range(self.n_init):\n",
    "            means.append(kmeans_plusplus(data, self.n_comp)[0])\n",
    "            \n",
    "        means = jnp.asarray(means)\n",
    "        \n",
    "        cov = jnp.expand_dims(jnp.eye(self.dim), 0)\n",
    "        cov = cov.repeat(self.n_comp, 0)\n",
    "        cov = jnp.expand_dims(cov, 0)\n",
    "        cov = cov.repeat(self.n_init, 0)\n",
    "        \n",
    "        self.means = means\n",
    "        self.cov = cov\n",
    "        self.weights = jnp.ones([self.n_init, self.n_comp]) / self.n_comp\n",
    "        \n",
    "    def km_init(self, data):\n",
    "        means = []\n",
    "        \n",
    "        for i in range(self.n_init):\n",
    "            km = KMeans(n_clusters=self.n_comp, n_init=1).fit(data)\n",
    "            means.append(km.cluster_centers_)\n",
    "            \n",
    "        cov = jnp.expand_dims(jnp.eye(self.dim), 0)\n",
    "        cov = cov.repeat(self.n_comp, 0)\n",
    "        cov = jnp.expand_dims(cov, 0)\n",
    "        cov = cov.repeat(self.n_init, 0)\n",
    "        \n",
    "        self.means = means\n",
    "        self.cov = cov\n",
    "        self.weights = jnp.ones([self.n_init, self.n_comp]) / self.n_comp\n",
    "            \n",
    "    def loglikelihood(self, data, n_init=0):\n",
    "        N = data.shape[0]\n",
    "        res = []\n",
    "        \n",
    "        exp_sq = lambda data, mean, cov: -1 / 2 * (data - mean).T @ jnp.linalg.inv(cov) @ (data - mean)\n",
    "        exp_sq_vmap = jax.vmap(exp_sq, (0, None, None), 0)\n",
    "        \n",
    "        for i in range(self.n_comp):\n",
    "            log_lik_data_comp = - self.dim / 2 * jnp.log(2 * jnp.pi) - 1 / 2 * jnp.log(jnp.linalg.det(self.cov[n_init][i]))\n",
    "            \n",
    "            res_exp_sq = exp_sq_vmap(data, self.means[n_init][i], self.cov[n_init][i])\n",
    "            log_lik_data_comp += res_exp_sq\n",
    "            res.append(log_lik_data_comp)\n",
    "        \n",
    "        res = jnp.asarray(res) + jnp.log(jnp.expand_dims(self.weights[i], 1))\n",
    "        return res\n",
    "        \n",
    "    def score(self, data):\n",
    "        ret_val = []\n",
    "        for i in range(self.n_init):\n",
    "            log_lik_i = self.loglikelihood(data, n_init=i)\n",
    "            log_lik_i = jax.scipy.special.logsumexp(log_lik_i, axis=0)\n",
    "            log_lik_i = log_lik_i.mean()\n",
    "            ret_val.append(log_lik_i)\n",
    "            \n",
    "        return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "48809866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Array(-3.75330067, dtype=float64)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.make_blobs(n_samples=100)[0]\n",
    "\n",
    "gmm_jax = GuassianMixture(dim=data.shape[1], n_comp=3, n_init=1)\n",
    "\n",
    "gmm_jax.fit(data, max_iter=5)\n",
    "print(gmm_jax.score(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "98bceebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "  Iteration 1\t time lapse 0.01567s\t ll change inf\n",
      "  Iteration 2\t time lapse 0.00092s\t ll change 0.00108\n",
      "  Iteration 3\t time lapse 0.00086s\t ll change 0.00025\n",
      "Initialization converged: True\t time lapse 0.01748s\t ll -3.75340\n",
      "Reference LogLik: -3.7532595853653423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Array(-3.75325959, dtype=float64)]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm_sklearn = GaussianMixture(3, verbose=2, verbose_interval=1)\n",
    "\n",
    "gmm_sklearn.fit(data)\n",
    "print(f'Reference LogLik: {gmm_sklearn.score(data)}')\n",
    "\n",
    "weights = gmm_sklearn.weights_\n",
    "means = gmm_sklearn.means_\n",
    "cov = gmm_sklearn.covariances_\n",
    "\n",
    "gmm_jax.weights = jnp.asarray(jnp.expand_dims(weights, 0).repeat(10, 0))\n",
    "gmm_jax.means = jnp.asarray(jnp.expand_dims(means, 0).repeat(10, 0))\n",
    "gmm_jax.cov = jnp.asarray(jnp.expand_dims(cov, 0).repeat(10, 0))\n",
    "\n",
    "gmm_jax.score(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbfc3d1",
   "metadata": {},
   "source": [
    "### Try on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c73982e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Array(10.93385717, dtype=float64), Array(10.85821529, dtype=float64), Array(10.84798625, dtype=float64), Array(10.85957055, dtype=float64), Array(10.85501042, dtype=float64), Array(10.91277241, dtype=float64), Array(10.86531793, dtype=float64), Array(10.84798625, dtype=float64), Array(10.91664935, dtype=float64), Array(10.85153885, dtype=float64)]\n"
     ]
    }
   ],
   "source": [
    "data = load_cloud_dataset()\n",
    "n_init = 10\n",
    "\n",
    "gmm_jax = GuassianMixture(dim=data.shape[1], n_comp=5, n_init=n_init)\n",
    "\n",
    "gmm_jax.fit(data, max_iter=10)\n",
    "\n",
    "print(gmm_jax.score(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a210094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.211747257375087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 10 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_cloud_dataset()\n",
    "\n",
    "gmm_sklearn = GaussianMixture(5, verbose=0, verbose_interval=1, max_iter=10, init_params='kmeans', n_init=n_init)\n",
    "\n",
    "gmm_sklearn.fit(data)\n",
    "\n",
    "print(gmm_sklearn.score(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6152d8",
   "metadata": {},
   "source": [
    "### Try on more challenging synthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8420ab76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Array(-9.5784723, dtype=float64)]\n",
      "[0.09847184 0.10335273 0.09829694 0.09478363 0.10178235 0.10238119\n",
      " 0.10483296 0.10070083 0.0932159  0.10218163]\n",
      "[Array(5.57020881, dtype=float64)]\n",
      "[0.09636037 0.10535736 0.09872072 0.09765784 0.10400059 0.09789174\n",
      " 0.105164   0.09758194 0.09674804 0.1005174 ]\n",
      "[Array(5.57085649, dtype=float64)]\n",
      "[0.09454035 0.10730969 0.09912313 0.10012078 0.10615426 0.09378679\n",
      " 0.10539643 0.09478114 0.09991338 0.09887405]\n",
      "[Array(5.57139572, dtype=float64)]\n",
      "[0.09298017 0.10921202 0.09951533 0.10221437 0.10824458 0.09002532\n",
      " 0.10553828 0.09226239 0.10274692 0.09726062]\n",
      "[Array(5.57184801, dtype=float64)]\n",
      "[0.09165158 0.11106568 0.09990549 0.10397957 0.11027172 0.08657005\n",
      " 0.10559613 0.08999337 0.10528368 0.09568274]\n",
      "[Array(5.57223052, dtype=float64)]\n",
      "[0.09052944 0.11287145 0.10029949 0.10545505 0.11223526 0.08338751\n",
      " 0.10557555 0.0879453  0.10755734 0.09414362]\n",
      "[Array(5.57255687, dtype=float64)]\n",
      "[0.08959156 0.11462987 0.10070149 0.10667645 0.11413444 0.08044787\n",
      " 0.10548147 0.08609274 0.10959938 0.09264473]\n",
      "[Array(5.57283787, dtype=float64)]\n",
      "[0.08881842 0.11634139 0.10111434 0.10767607 0.11596844 0.07772471\n",
      " 0.1053184  0.08441326 0.11143862 0.09118636]\n",
      "[Array(5.57308207, dtype=float64)]\n",
      "[0.08819281 0.11800649 0.10153995 0.10848277 0.11773649 0.07519468\n",
      " 0.10509058 0.08288716 0.11310106 0.08976801]\n",
      "[Array(5.57329624, dtype=float64)]\n",
      "[0.08769965 0.11962583 0.10197952 0.10912211 0.119438   0.07283723\n",
      " 0.10480205 0.08149711 0.11460988 0.08838862]\n",
      "[Array(5.57348578, dtype=float64)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_synth = load_synthetic_dataset('synth_dim_10.npy')\n",
    "\n",
    "gmm_jax = GuassianMixture(dim=data_synth.shape[1], n_comp=10, n_init=1)\n",
    "\n",
    "gmm_jax.km_init(data_synth)\n",
    "\n",
    "print(gmm_jax.score(data_synth))\n",
    "\n",
    "gmm_jax.fit(data_synth, max_iter=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ec0d7f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "  Iteration 1\t time lapse 0.06119s\t ll change inf\n",
      "  Iteration 2\t time lapse 0.00853s\t ll change 0.02054\n",
      "  Iteration 3\t time lapse 0.00586s\t ll change 0.01005\n",
      "  Iteration 4\t time lapse 0.00576s\t ll change 0.00995\n",
      "  Iteration 5\t time lapse 0.00578s\t ll change 0.00394\n",
      "  Iteration 6\t time lapse 0.00574s\t ll change 0.00242\n",
      "  Iteration 7\t time lapse 0.00577s\t ll change 0.00252\n",
      "  Iteration 8\t time lapse 0.00575s\t ll change 0.00313\n",
      "  Iteration 9\t time lapse 0.00580s\t ll change 0.00330\n",
      "  Iteration 10\t time lapse 0.00571s\t ll change 0.00367\n",
      "Initialization converged: False\t time lapse 0.11590s\t ll 10.86906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-32 {color: black;background-color: white;}#sk-container-id-32 pre{padding: 0;}#sk-container-id-32 div.sk-toggleable {background-color: white;}#sk-container-id-32 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-32 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-32 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-32 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-32 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-32 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-32 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-32 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-32 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-32 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-32 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-32 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-32 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-32 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-32 div.sk-item {position: relative;z-index: 1;}#sk-container-id-32 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-32 div.sk-item::before, #sk-container-id-32 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-32 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-32 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-32 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-32 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-32 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-32 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-32 div.sk-label-container {text-align: center;}#sk-container-id-32 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-32 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-32\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianMixture(max_iter=10, n_components=10, verbose=2, verbose_interval=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" checked><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianMixture</label><div class=\"sk-toggleable__content\"><pre>GaussianMixture(max_iter=10, n_components=10, verbose=2, verbose_interval=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianMixture(max_iter=10, n_components=10, verbose=2, verbose_interval=1)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gmm_sklearn = GaussianMixture(10, verbose=2, verbose_interval=1, max_iter=10, init_params='kmeans')\n",
    "\n",
    "gmm_sklearn.fit(data_synth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e95de67",
   "metadata": {},
   "source": [
    "## Time measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d0c30091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/mixture/_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for one EM step: 0.004978680610656738 s +- 0.0018394913234751795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for one EM step jax: 0.16771907806396485 s +- 0.04918234536471882\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()['data']\n",
    "data = load_synthetic_dataset('synth_dim_10.npy')\n",
    "\n",
    "\n",
    "n_runs = 10\n",
    "\n",
    "time_storage = []\n",
    "for i in range(n_runs):\n",
    "    gmm_sklearn = GaussianMixture(3, verbose=0, verbose_interval=1, max_iter=1, init_params='kmeans')\n",
    "    \n",
    "    start = time()\n",
    "\n",
    "    gmm_sklearn.fit(data)\n",
    "    \n",
    "    time_storage.append(time() - start)\n",
    "    \n",
    "print(f'Time for one EM step: {np.mean(time_storage)} s +- {np.std(time_storage)}')\n",
    "\n",
    "time_storage = []\n",
    "for i in range(n_runs):\n",
    "    \n",
    "    gmm_jax = GuassianMixture(dim=data.shape[1], n_comp=3, n_init=1)\n",
    "\n",
    "    start = time()\n",
    "    gmm_jax.km_init(data)\n",
    "    gmm_jax.fit(data, max_iter=1)\n",
    "    \n",
    "    time_storage.append(time() - start)\n",
    "\n",
    "print(f'Time for one EM step jax: {np.mean(time_storage)} s +- {np.std(time_storage)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2efbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
